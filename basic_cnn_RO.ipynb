{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this as as base for CNN model\n",
    "# https://www.kaggle.com/sunnyguha/basic-cnn-starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images - 1000 to begin with and on a lazy basis\n",
    "#   need 1000 images that correspond to 1000 y_train\n",
    "#   images as np.array(1000,size,size,3) and np.array(1000,1)\n",
    "#   user Keras flow from directory\n",
    "\n",
    "# CNN Model\n",
    "#   Layers\n",
    "#   Compile\n",
    "#     During compile stage, set the parameter that you want to minimize\n",
    "#     Weighted column\n",
    "\n",
    "\n",
    "# View results\n",
    "\n",
    "# Check\n",
    "#   In the case of false positives for a class, is it more likely that the result is of a different class or that it is negative in all classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables\n",
    "# un-comment as they are used\n",
    "# batch_size=32\n",
    "# validation_ratio=0.1\n",
    "# sample_size=2000\n",
    "# epochs=3\n",
    "# img_size=512\n",
    "data_path = \"../data/\"   # used when calling DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259_epidural</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_63eb1e259_intraparenchymal</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_63eb1e259_intraventricular</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_63eb1e259_subarachnoid</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259.dcm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_63eb1e259_subdural</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259.dcm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID  Label          filename\n",
       "0          ID_63eb1e259_epidural      0  ID_63eb1e259.dcm\n",
       "1  ID_63eb1e259_intraparenchymal      0  ID_63eb1e259.dcm\n",
       "2  ID_63eb1e259_intraventricular      0  ID_63eb1e259.dcm\n",
       "3      ID_63eb1e259_subarachnoid      0  ID_63eb1e259.dcm\n",
       "4          ID_63eb1e259_subdural      0  ID_63eb1e259.dcm"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(data_path + 'stage_1_train.csv')\n",
    "train['filename'] = train['ID'].apply(lambda x: \"ID_\" + x.split('_')[1] + \".dcm\")\n",
    "\n",
    "\n",
    "read_data = train.copy()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataGenerator class based on code written by https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.  The DataGenerator class inherits from the Keras utils.Sequence class and is used to read and serve the train data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs_labels, data_path = '', batch_size=100, dim=(512,512)):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs_labels\n",
    "        self.data_path = data_path\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs['filename'][k] for k in indexes]\n",
    "        list_label_temp=[[int(self.list_IDs['any'][i]),int(self.list_IDs['epidural'][i]),int(self.list_IDs['intraparenchymal'][i]),int(self.list_IDs['intraventricular'][i]),int(self.list_IDs['subarachnoid'][i]),int(self.list_IDs['subdural'][i])] for i in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp,list_label_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp,list_label_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            ds=pydicom.dcmread(self.data_path+'stage_1_train_images/' +list_IDs_temp[i] )\n",
    "            temp=ds.pixel_array\n",
    "            window_center , window_width, intercept, slope = get_windowing(ds)\n",
    "            img = window_image(temp, 50, 100, intercept, slope)\n",
    "            resized = cv2.resize(img, (200, 200))\n",
    "            X.append(resized)       \n",
    "        X=np.array(X).reshape(-1,200,200,1)\n",
    "        y_train=np.asarray(list_label_temp) \n",
    "        return X,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
