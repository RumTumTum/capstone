{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this as as base for CNN model\n",
    "# https://www.kaggle.com/sunnyguha/basic-cnn-starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import images - 1000 to begin with and on a lazy basis\n",
    "#   need 1000 images that correspond to 1000 y_train\n",
    "#   images as np.array(1000,size,size,3) and np.array(1000,1)\n",
    "#   user Keras flow from directory\n",
    "\n",
    "# CNN Model\n",
    "#   Layers\n",
    "#   Compile\n",
    "#     During compile stage, set the parameter that you want to minimize\n",
    "#     Weighted column\n",
    "\n",
    "\n",
    "# View results\n",
    "\n",
    "# Check\n",
    "#   In the case of false positives for a class, is it more likely that the result is of a different class or that it is negative in all classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 2.7.13\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.3 (default, Sep 27 2018, 17:25:39) \\n[GCC 6.3.0 20170516]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-a041d8f072f9>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-a041d8f072f9>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    import \"tensorflow-gpu\" as tf\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals #to check for gpu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Images\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "# Batching for DataGenerator\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "\n",
    "# Keras and Tensorflow\n",
    "import tensorflow-gpu as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "print(\"Keras: \",keras.__version__)\n",
    "print(\"Tensorflow: \",tf.__version__)\n",
    "# print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16940113509886823645\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 179859568340977389\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-a7323e8bc0e7>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-a7323e8bc0e7>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    a = tf.get_variable(f\"a_{i}\", [2, 3], initializer=tf.random_uniform_initializer(-1, 1))\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "c = []\n",
    "for i, d in enumerate(['/gpu:0', '/gpu:1', '/gpu:2']):\n",
    "    with tf.device(d):\n",
    "        a = tf.get_variable(f\"a_{i}\", [2, 3], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "        b = tf.get_variable(f\"b_{i}\", [3, 2], initializer=tf.random_uniform_initializer(-1, 1))\n",
    "        c.append(tf.matmul(a, b))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.add_n(c)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The issue has to do with the parameter I load into DataGenerator\n",
    "\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "# import os\n",
    "# from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import keras\n",
    "\n",
    "# from tensorflow.python.ops import array_ops\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables\n",
    "# un-comment as they are used\n",
    "batch_size=100\n",
    "# validation_ratio=0.1\n",
    "# sample_size=2000\n",
    "# epochs=3\n",
    "# img_size=512\n",
    "data_path = \"../data/\"   # used when calling DataGenerator\n",
    "random_gen = np.random.RandomState(seed=12345)  # seed is not working\n",
    "\n",
    "# dataset size to use during model building. Remove these later.\n",
    "train_size = 10000\n",
    "valid_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>filename</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259_epidural</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259.dcm</td>\n",
       "      <td>epidural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_63eb1e259_intraparenchymal</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259.dcm</td>\n",
       "      <td>intraparenchymal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_63eb1e259_intraventricular</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259.dcm</td>\n",
       "      <td>intraventricular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_63eb1e259_subarachnoid</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259.dcm</td>\n",
       "      <td>subarachnoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_63eb1e259_subdural</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_63eb1e259.dcm</td>\n",
       "      <td>subdural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              ID  Label          filename              type\n",
       "0          ID_63eb1e259_epidural      0  ID_63eb1e259.dcm          epidural\n",
       "1  ID_63eb1e259_intraparenchymal      0  ID_63eb1e259.dcm  intraparenchymal\n",
       "2  ID_63eb1e259_intraventricular      0  ID_63eb1e259.dcm  intraventricular\n",
       "3      ID_63eb1e259_subarachnoid      0  ID_63eb1e259.dcm      subarachnoid\n",
       "4          ID_63eb1e259_subdural      0  ID_63eb1e259.dcm          subdural"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.read_csv(data_path + 'stage_1_train.csv')\n",
    "train_raw['filename'] = train_raw['ID'].apply(lambda x: \"ID_\" + x.split('_')[1] + \".dcm\")\n",
    "train_raw['type'] = train_raw['ID'].apply(lambda x: x.split('_')[2])\n",
    "\n",
    "train_raw.reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_000039fa0.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_00005679d.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_00008ce3c.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_0000950d7.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_0000aee4b.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type          filename  any  epidural  intraparenchymal  intraventricular  \\\n",
       "0     ID_000039fa0.dcm    0         0                 0                 0   \n",
       "1     ID_00005679d.dcm    0         0                 0                 0   \n",
       "2     ID_00008ce3c.dcm    0         0                 0                 0   \n",
       "3     ID_0000950d7.dcm    0         0                 0                 0   \n",
       "4     ID_0000aee4b.dcm    0         0                 0                 0   \n",
       "\n",
       "type  subarachnoid  subdural  \n",
       "0                0         0  \n",
       "1                0         0  \n",
       "2                0         0  \n",
       "3                0         0  \n",
       "4                0         0  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pivot = train_raw[['Label', 'filename', 'type']].drop_duplicates().pivot(\n",
    "    index='filename', columns='type', values='Label').reset_index()\n",
    "\n",
    "train_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "any                 97103\n",
       "epidural             2761\n",
       "intraparenchymal    32564\n",
       "intraventricular    23766\n",
       "subarachnoid        32122\n",
       "subdural            42496\n",
       "dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_pivot.sum()\n",
    "# extract y_train (class vector)\n",
    "x_y_train.iloc[:,1:].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df for y_train to get out of pivot table format\n",
    "train = pd.DataFrame(\n",
    "    train_pivot,columns=[\n",
    "        'filename',\n",
    "        'any',\n",
    "        'epidural',\n",
    "        'intraparenchymal',\n",
    "        'intraventricular',\n",
    "        'subarachnoid',\n",
    "        'subdural'\n",
    "    ])\n",
    "\n",
    "# # extract y_train (class vector)\n",
    "# y_train = x_y_train.iloc[:,1:].copy()\n",
    "\n",
    "# # extract x_train filenames\n",
    "# x_train_id = train.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions to extract the correct window-image. These have been adapted from https://www.kaggle.com/allunia/rsna-ih-detection-eda and references therin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_image(img, window_center,window_width, intercept, slope, rescale=True):\n",
    "\n",
    "    img = (img*slope +intercept)\n",
    "    img_min = window_center - window_width//2\n",
    "    img_max = window_center + window_width//2\n",
    "    img[img<img_min] = img_min\n",
    "    img[img>img_max] = img_max\n",
    "    \n",
    "    if rescale:\n",
    "        # Extra rescaling to 0-1, not in the original notebook\n",
    "        img = (img - img_min) / (img_max - img_min)\n",
    "    \n",
    "    return img\n",
    "    \n",
    "def get_first_of_dicom_field_as_int(x):\n",
    "    #get x[0] as in int is x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n",
    "    if type(x) == pydicom.multival.MultiValue:\n",
    "        return int(x[0])\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "def get_windowing(data):\n",
    "    dicom_fields = [data[('0028','1050')].value, #window center\n",
    "                    data[('0028','1051')].value, #window width\n",
    "                    data[('0028','1052')].value, #intercept\n",
    "                    data[('0028','1053')].value] #slope\n",
    "    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataGenerator class based on code written by https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.  The DataGenerator class inherits from the Keras utils.Sequence class and is used to read and serve the train data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs_labels, data_path = '', batch_size=100, dim=(512,512)):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.list_IDs = list_IDs_labels\n",
    "        self.data_path = data_path\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs['filename'][k] for k in indexes]\n",
    "        list_label_temp=[[int(self.list_IDs['any'][i]),int(self.list_IDs['epidural'][i]),int(self.list_IDs['intraparenchymal'][i]),int(self.list_IDs['intraventricular'][i]),int(self.list_IDs['subarachnoid'][i]),int(self.list_IDs['subdural'][i])] for i in indexes]\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp,list_label_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp,list_label_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            ds=pydicom.dcmread(self.data_path+'stage_1_train_images/' +list_IDs_temp[i] )\n",
    "            temp=ds.pixel_array\n",
    "            window_center , window_width, intercept, slope = get_windowing(ds)\n",
    "            img = window_image(temp, 50, 100, intercept, slope)\n",
    "            resized = cv2.resize(img, (200, 200))\n",
    "            X.append(resized)       \n",
    "        X=np.array(X).reshape(-1,200,200,1)\n",
    "        y_train=np.asarray(list_label_temp) \n",
    "        return X,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_35bc62b1e.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_a3c9515cc.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_1f7bd56ae.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_0ad2f7be5.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_da790a955.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type          filename  any  epidural  intraparenchymal  intraventricular  \\\n",
       "0     ID_35bc62b1e.dcm    0         0                 0                 0   \n",
       "1     ID_a3c9515cc.dcm    0         0                 0                 0   \n",
       "2     ID_1f7bd56ae.dcm    0         0                 0                 0   \n",
       "3     ID_0ad2f7be5.dcm    0         0                 0                 0   \n",
       "4     ID_da790a955.dcm    0         0                 0                 0   \n",
       "\n",
       "type  subarachnoid  subdural  \n",
       "0                0         0  \n",
       "1                0         0  \n",
       "2                0         0  \n",
       "3                0         0  \n",
       "4                0         0  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replicating a version that works\n",
    "# can remove later\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "train = shuffle(train_pivot)\n",
    "train_sample=train\n",
    "train_sample2=train_sample.reset_index(drop=True)\n",
    "train_sample2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>filename</th>\n",
       "      <th>any</th>\n",
       "      <th>epidural</th>\n",
       "      <th>intraparenchymal</th>\n",
       "      <th>intraventricular</th>\n",
       "      <th>subarachnoid</th>\n",
       "      <th>subdural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_8b10efc1e.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_f6e2d3233.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_897e94a32.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_66eda233e.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_67c75ae26.dcm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type          filename  any  epidural  intraparenchymal  intraventricular  \\\n",
       "0     ID_8b10efc1e.dcm    0         0                 0                 0   \n",
       "1     ID_f6e2d3233.dcm    0         0                 0                 0   \n",
       "2     ID_897e94a32.dcm    0         0                 0                 0   \n",
       "3     ID_66eda233e.dcm    0         0                 0                 0   \n",
       "4     ID_67c75ae26.dcm    0         0                 0                 0   \n",
       "\n",
       "type  subarachnoid  subdural  \n",
       "0                0         0  \n",
       "1                0         0  \n",
       "2                0         0  \n",
       "3                0         0  \n",
       "4                0         0  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid=train_sample2[100000:120000]\n",
    "valid=valid.reset_index(drop=True)\n",
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen=DataGenerator(train_sample2[0:100],data_path = data_path)#increase back to 100000\n",
    "validgen=DataGenerator(valid,data_path = data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Disabled for the moment - later re-enable\n",
    "# train_actual = train[0:train_size]\n",
    "# train_valid = train[train_size:(train_size+valid_size)]\n",
    "\n",
    "# traingen=DataGenerator(train_actual,data_path = data_path, batch_size=batch_size) #increase back to 100000\n",
    "# validgen=DataGenerator(train_valid,data_path = data_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an unbalanced data-set it is good to define a custom loss function like the focal loss. We will borrowed the code for this from https://www.kaggle.com/xhlulu/rsna-intracranial-simple-densenet-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(prediction_tensor, target_tensor, weights=None, alpha=0.25, gamma=2):\n",
    "    r\"\"\"Compute focal loss for predictions.\n",
    "        Multi-labels Focal loss formula:\n",
    "            FL = -alpha * (z-p)^gamma * log(p) -(1-alpha) * p^gamma * log(1-p)\n",
    "                 ,which alpha = 0.25, gamma = 2, p = sigmoid(x), z = target_tensor.\n",
    "    Args:\n",
    "     prediction_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing the predicted logits for each class\n",
    "     target_tensor: A float tensor of shape [batch_size, num_anchors,\n",
    "        num_classes] representing one-hot encoded classification targets\n",
    "     weights: A float tensor of shape [batch_size, num_anchors]\n",
    "     alpha: A scalar tensor for focal loss alpha hyper-parameter\n",
    "     gamma: A scalar tensor for focal loss gamma hyper-parameter\n",
    "    Returns:\n",
    "        loss: A (scalar) tensor representing the value of the loss function\n",
    "    \"\"\"\n",
    "    sigmoid_p = tf.nn.sigmoid(prediction_tensor)\n",
    "    zeros = array_ops.zeros_like(sigmoid_p, dtype=sigmoid_p.dtype)\n",
    "    \n",
    "    # For poitive prediction, only need consider front part loss, back part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so poitive coefficient = z - p.\n",
    "    pos_p_sub = array_ops.where(target_tensor > zeros, target_tensor - sigmoid_p, zeros)\n",
    "    \n",
    "    # For negative prediction, only need consider back part loss, front part is 0;\n",
    "    # target_tensor > zeros <=> z=1, so negative coefficient = 0.\n",
    "    neg_p_sub = array_ops.where(target_tensor > zeros, zeros, sigmoid_p)\n",
    "    per_entry_cross_ent = - alpha * (pos_p_sub ** gamma) * tf.log(tf.clip_by_value(sigmoid_p, 1e-8, 1.0)) \\\n",
    "                          - (1 - alpha) * (neg_p_sub ** gamma) * tf.log(tf.clip_by_value(1.0 - sigmoid_p, 1e-8, 1.0))\n",
    "    return tf.reduce_sum(per_entry_cross_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have both Input=X , Category=y_trest we can train a basic barebones model.\n",
    "Here we have a model which is like ==   CNN -> CNN->  Flatten --> Dense ---> Dense(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 220s 220s/step - loss: 0.5895 - accuracy: 0.4400 - val_loss: 0.5915 - val_accuracy: 0.0982\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 113s 113s/step - loss: 0.5324 - accuracy: 0.1100 - val_loss: 0.5832 - val_accuracy: 0.0468\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(200, 200,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(5,5)))\n",
    "\n",
    "model.add(Flatten())  \n",
    "\n",
    "# model.add(Dense(100))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(6))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss=focal_loss,\n",
    "#                optimizer='adam',\n",
    "#                metrics=['accuracy'])\n",
    "\n",
    "# model.fit(X,y_train,batch_size=32,epochs=6,validation_split=0.5)\n",
    "history=model.fit_generator(\n",
    "    generator=traingen,\n",
    "    validation_data=validgen,\n",
    "    use_multiprocessing=True,\n",
    "    workers=1,\n",
    "    epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's this error?\n",
    "# things not yet imported, below\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
