{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to achieve:\n",
    "- Run binary and get a good confusion matrix\n",
    "- Run multi-label (5 labels) and get a good confusion matrix on any\n",
    "- Add callback to save weights and reimport them each time\n",
    "- Add the VGG16 or Densenet50\n",
    "- Make the presentation based on this\n",
    "- Add anything else only afterwards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python:  3.5.3 \n",
      "Keras:  2.3.0\n",
      "Tensorflow:  2.0.0\n",
      "GPU Available:  True\n",
      "Num GPUs Available:  1\n",
      "\n",
      "All devices:\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU')\n",
      "PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# Checking GPU availability\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals #to check for gpu\n",
    "\n",
    "# Custom libraries\n",
    "from custom_libraries import file_saving\n",
    "from custom_libraries import image_processing\n",
    "from custom_libraries import import_data\n",
    "from custom_libraries import model_support\n",
    "\n",
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Images\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "# Batching for DataGenerator\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "\n",
    "# Keras, Tensorflow and other model related\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Checking devices and system settings\n",
    "import sys\n",
    "print(\"Python: \", sys.version[:6])\n",
    "print(\"Keras: \",keras.__version__)\n",
    "print(\"Tensorflow: \",tf.__version__)\n",
    "print(\"GPU Available: \",tf.test.is_gpu_available())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"\\nAll devices:\", *tf.config.experimental.list_physical_devices(),sep=\"\\n\")\n",
    "\n",
    "# saving to cloud storage\n",
    "from google.cloud import storage\n",
    "from custom_libraries import gcloud_storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set global variables\n",
    "batch_size=128\n",
    "dim=(512,512)\n",
    "data_path = \"../data/\"   # used when calling DataGenerator\n",
    "random_seed = 12345\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data and Create Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = import_data.clean_data_csv(shuffle_data = True)\n",
    "data = import_data.balanced_images_binary(image_list)\n",
    "train_data, valid_data = train_test_split(data, test_size = 0.15, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen=image_processing.DataGenerator_single_class(train_data,data_path = data_path, batch_size = batch_size)\n",
    "validgen=image_processing.DataGenerator_single_class(valid_data,data_path = data_path, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_test = train_data[0:batch_size*5]\n",
    "valid_data_test = valid_data[0:batch_size*1]\n",
    "\n",
    "traingen_test=image_processing.DataGenerator_single_class(train_data_test,data_path = data_path, batch_size = batch_size)\n",
    "validgen_test=image_processing.DataGenerator_single_class(valid_data_test,data_path = data_path, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 165075 entries, 168778 to 77285\n",
      "Data columns (total 7 columns):\n",
      "filename            165075 non-null object\n",
      "any                 165075 non-null int64\n",
      "epidural            165075 non-null int64\n",
      "intraparenchymal    165075 non-null int64\n",
      "intraventricular    165075 non-null int64\n",
      "subarachnoid        165075 non-null int64\n",
      "subdural            165075 non-null int64\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_notes = \"165k train images, balanced across any and none, binary, 512\"\n",
    "model_tags = ['binary', 'img_size:512']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_notes = \"test, binary, 512\"\n",
    "# model_tags = ['binary', 'img_size:512', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1264/1289 [============================>.] - ETA: 33s - loss: 0.4977 - accuracy: 0.7570"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The length of the pixel data in the dataset (153710 bytes) doesn't match the expected length (524288 bytes). The dataset may be corrupted or there may be an issue with the pixel data handler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 571, in get_index\n    return _SHARED_SEQUENCES[uid][i]\n  File \"/home/jupyter/capstone/custom_libraries/image_processing.py\", line 132, in __getitem__\n    X, y = self.__data_generation(list_IDs_temp,list_label_temp)\n  File \"/home/jupyter/capstone/custom_libraries/image_processing.py\", line 150, in __data_generation\n    raw=ds.pixel_array\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/pydicom/dataset.py\", line 1362, in pixel_array\n    self.convert_pixel_data()\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/pydicom/dataset.py\", line 1308, in convert_pixel_data\n    raise last_exception\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/pydicom/dataset.py\", line 1276, in convert_pixel_data\n    arr = handler.get_pixeldata(self)\n  File \"/home/jupyter/.local/lib/python3.5/site-packages/pydicom/pixel_data_handlers/numpy_handler.py\", line 257, in get_pixeldata\n    .format(actual_length, padded_expected_len)\nValueError: The length of the pixel data in the dataset (153710 bytes) doesn't match the expected length (524288 bytes). The dataset may be corrupted or there may be an issue with the pixel data handler.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-04366e56bf66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     epochs=30)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mfile_saving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_notes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_notes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The length of the pixel data in the dataset (153710 bytes) doesn't match the expected length (524288 bytes). The dataset may be corrupted or there may be an issue with the pixel data handler."
     ]
    }
   ],
   "source": [
    "# Add weighted log loss - https://www.kaggle.com/akensert/inceptionv3-prev-resnet50-keras-baseline-model\n",
    "\n",
    "model_notes = model_notes\n",
    "model_tags = model_tags\n",
    "generator=traingen\n",
    "validation_data=validgen,\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(dim[0], dim[1],1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(5,5)))\n",
    "\n",
    "model.add(Flatten())  \n",
    "\n",
    "# model.add(Dense(100))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# for 6 classes\n",
    "model.add(Dense(6, activation = 'sigmoid'))\n",
    "\n",
    "# for 1 class\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "# originally the above. Why use binary vs categorical\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss=focal_loss,\n",
    "#                optimizer='adam',\n",
    "#                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(X,y_train,batch_size=32,epochs=6,validation_split=0.5)\n",
    "history=model.fit_generator(\n",
    "    generator=generator,\n",
    "    validation_data=validation_data,\n",
    "    use_multiprocessing=True,\n",
    "    workers=11,\n",
    "    epochs=30)\n",
    "\n",
    "file_saving.save_model(model, return_df=True, model_notes=model_notes).tail(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(generator=validgen_test,use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_confusion_matrix(valid_data_test['any'],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig('models/latest_model_accuracy.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig('models/latest_model_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Previous Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(root = 'models/', records_output = True, model_output = False, model_file_path = \"\"):\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    model_records_path = root+'model_records.csv'\n",
    "    df = pd.read_csv(model_records_path)\n",
    "    if not model_output:\n",
    "        return df\n",
    "    else:\n",
    "        \n",
    "        model = tf.keras.models.load_model(model_file_path)\n",
    "        if records_output:\n",
    "            return df, model\n",
    "        else:\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>layers</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_notes</th>\n",
       "      <th>model_path</th>\n",
       "      <th>model_tags</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>train_size</th>\n",
       "      <th>validation_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-11T181803_model.h5</td>\n",
       "      <td>test run with ~1000 images, using save_model(p...</td>\n",
       "      <td>models/2019-10-11T181803_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-11 18:18:03.877753</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-13T224638_model.h5</td>\n",
       "      <td>test run with ~1000 images and ~200 valid size...</td>\n",
       "      <td>models/2019-10-13T224638_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-13 22:46:38.409506</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-13T231208_model.h5</td>\n",
       "      <td>test run with ~1000 images and ~200 valid size...</td>\n",
       "      <td>models/2019-10-13T231208_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-13 23:12:08.724183</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-14T153044_model.h5</td>\n",
       "      <td>test run with ~1000 images and ~200 valid size...</td>\n",
       "      <td>models/2019-10-14T153044_model.h5</td>\n",
       "      <td>{'tensorflow', 'keras'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14 15:30:44.529041</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-14T155036_model.h5</td>\n",
       "      <td>test run with ~1000 images and ~200 valid size...</td>\n",
       "      <td>models/2019-10-14T155036_model.h5</td>\n",
       "      <td>{'tensorflow', 'keras'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14 15:50:36.173946</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-14T174235_model.h5</td>\n",
       "      <td>test run with ~1000 images and ~200 valid size...</td>\n",
       "      <td>models/2019-10-14T174235_model.h5</td>\n",
       "      <td>{'tensorflow', 'keras'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14 17:42:35.160266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-14T174315_model.h5</td>\n",
       "      <td>test run with ~1000 images and ~200 valid size...</td>\n",
       "      <td>models/2019-10-14T174315_model.h5</td>\n",
       "      <td>{'tensorflow', 'keras'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14 17:43:15.894860</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-14T193159_model.h5</td>\n",
       "      <td>testing</td>\n",
       "      <td>models/2019-10-14T193159_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14 19:31:59.079340</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-14T194331_model.h5</td>\n",
       "      <td>24600 images, balanced across each category in...</td>\n",
       "      <td>models/2019-10-14T194331_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14 19:43:31.080304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-19T020705_model.h5</td>\n",
       "      <td>test</td>\n",
       "      <td>models/2019-10-19T020705_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-19 02:07:05.253117</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epochs layers                  model_name  \\\n",
       "8        1     []  2019-10-11T181803_model.h5   \n",
       "9        1     []  2019-10-13T224638_model.h5   \n",
       "10       1     []  2019-10-13T231208_model.h5   \n",
       "11       1     []  2019-10-14T153044_model.h5   \n",
       "12       1     []  2019-10-14T155036_model.h5   \n",
       "13       1     []  2019-10-14T174235_model.h5   \n",
       "14       1     []  2019-10-14T174315_model.h5   \n",
       "15       1     []  2019-10-14T193159_model.h5   \n",
       "16       1     []  2019-10-14T194331_model.h5   \n",
       "17       1     []  2019-10-19T020705_model.h5   \n",
       "\n",
       "                                          model_notes  \\\n",
       "8   test run with ~1000 images, using save_model(p...   \n",
       "9   test run with ~1000 images and ~200 valid size...   \n",
       "10  test run with ~1000 images and ~200 valid size...   \n",
       "11  test run with ~1000 images and ~200 valid size...   \n",
       "12  test run with ~1000 images and ~200 valid size...   \n",
       "13  test run with ~1000 images and ~200 valid size...   \n",
       "14  test run with ~1000 images and ~200 valid size...   \n",
       "15                                            testing   \n",
       "16  24600 images, balanced across each category in...   \n",
       "17                                               test   \n",
       "\n",
       "                           model_path               model_tags  num_layers  \\\n",
       "8   models/2019-10-11T181803_model.h5  {'keras', 'tensorflow'}           0   \n",
       "9   models/2019-10-13T224638_model.h5  {'keras', 'tensorflow'}           0   \n",
       "10  models/2019-10-13T231208_model.h5  {'keras', 'tensorflow'}           0   \n",
       "11  models/2019-10-14T153044_model.h5  {'tensorflow', 'keras'}           0   \n",
       "12  models/2019-10-14T155036_model.h5  {'tensorflow', 'keras'}           0   \n",
       "13  models/2019-10-14T174235_model.h5  {'tensorflow', 'keras'}           0   \n",
       "14  models/2019-10-14T174315_model.h5  {'tensorflow', 'keras'}           0   \n",
       "15  models/2019-10-14T193159_model.h5  {'keras', 'tensorflow'}           0   \n",
       "16  models/2019-10-14T194331_model.h5  {'keras', 'tensorflow'}           0   \n",
       "17  models/2019-10-19T020705_model.h5  {'keras', 'tensorflow'}           0   \n",
       "\n",
       "    optimizer  score                   timestamp  train_size  validation_size  \n",
       "8           1      1  2019-10-11 18:18:03.877753           1                1  \n",
       "9           1      1  2019-10-13 22:46:38.409506           1                1  \n",
       "10          1      1  2019-10-13 23:12:08.724183           1                1  \n",
       "11          1      1  2019-10-14 15:30:44.529041           1                1  \n",
       "12          1      1  2019-10-14 15:50:36.173946           1                1  \n",
       "13          1      1  2019-10-14 17:42:35.160266           1                1  \n",
       "14          1      1  2019-10-14 17:43:15.894860           1                1  \n",
       "15          1      1  2019-10-14 19:31:59.079340           1                1  \n",
       "16          1      1  2019-10-14 19:43:31.080304           1                1  \n",
       "17          1      1  2019-10-19 02:07:05.253117           1                1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See df of most recent records\n",
    "records = load_model(records_output = True, model_output = False)\n",
    "last_record = list(records.model_path)[-1]\n",
    "records.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model last model\n",
    "_, loaded_model = load_model(records_output = True, model_output = True, model_file_path = last_record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, temp_model = load_model(records_output = True, model_output = True, model_file_path = 'models/2019-10-14T194331_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barebones function to save. Used for testing the save functions\n",
    "\n",
    "model_path = 'models/2019-10-13T224638_model.h5'\n",
    "# keras.models.save_model(model, model_path)\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worked-1\n",
      "worked-2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>layers</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_notes</th>\n",
       "      <th>model_path</th>\n",
       "      <th>model_tags</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>train_size</th>\n",
       "      <th>validation_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T211053_model.h5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>models/2019-10-10T211053_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 21:10:53.796514</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T211056_model.h5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>models/2019-10-10T211056_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 21:10:56.404866</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T211112_model.h5</td>\n",
       "      <td>hello</td>\n",
       "      <td>models/2019-10-10T211112_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 21:11:12.708478</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T211115_model.h5</td>\n",
       "      <td>hello</td>\n",
       "      <td>models/2019-10-10T211115_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 21:11:15.211067</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T211116_model.h5</td>\n",
       "      <td>hello</td>\n",
       "      <td>models/2019-10-10T211116_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 21:11:16.248314</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T211129_model.h5</td>\n",
       "      <td>hello</td>\n",
       "      <td>models/2019-10-10T211129_model.h5</td>\n",
       "      <td>{keras, tensorflow}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 21:11:29.360498</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs layers                  model_name model_notes  \\\n",
       "0       1     []  2019-10-10T211053_model.h5         NaN   \n",
       "1       1     []  2019-10-10T211056_model.h5         NaN   \n",
       "2       1     []  2019-10-10T211112_model.h5       hello   \n",
       "3       1     []  2019-10-10T211115_model.h5       hello   \n",
       "4       1     []  2019-10-10T211116_model.h5       hello   \n",
       "5       1     []  2019-10-10T211129_model.h5       hello   \n",
       "\n",
       "                          model_path               model_tags  num_layers  \\\n",
       "0  models/2019-10-10T211053_model.h5  {'keras', 'tensorflow'}           0   \n",
       "1  models/2019-10-10T211056_model.h5  {'keras', 'tensorflow'}           0   \n",
       "2  models/2019-10-10T211112_model.h5  {'keras', 'tensorflow'}           0   \n",
       "3  models/2019-10-10T211115_model.h5  {'keras', 'tensorflow'}           0   \n",
       "4  models/2019-10-10T211116_model.h5  {'keras', 'tensorflow'}           0   \n",
       "5  models/2019-10-10T211129_model.h5      {keras, tensorflow}           0   \n",
       "\n",
       "   optimizer  score                   timestamp  train_size  validation_size  \n",
       "0          1      1  2019-10-10 21:10:53.796514           1                1  \n",
       "1          1      1  2019-10-10 21:10:56.404866           1                1  \n",
       "2          1      1  2019-10-10 21:11:12.708478           1                1  \n",
       "3          1      1  2019-10-10 21:11:15.211067           1                1  \n",
       "4          1      1  2019-10-10 21:11:16.248314           1                1  \n",
       "5          1      1  2019-10-10 21:11:29.360498           1                1  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = save_model(model, model_tags = [],return_df=True, model_notes=\"hello\")\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>layers</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_path</th>\n",
       "      <th>model_tags</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>score</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>train_size</th>\n",
       "      <th>validation_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T202614_model.h5</td>\n",
       "      <td>models/2019-10-10T202614_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 20:26:14.109413</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T202617_model.h5</td>\n",
       "      <td>models/2019-10-10T202617_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 20:26:17.506235</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T202618_model.h5</td>\n",
       "      <td>models/2019-10-10T202618_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 20:26:18.759291</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T202619_model.h5</td>\n",
       "      <td>models/2019-10-10T202619_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 20:26:19.641559</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T202620_model.h5</td>\n",
       "      <td>models/2019-10-10T202620_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 20:26:20.819121</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T202621_model.h5</td>\n",
       "      <td>models/2019-10-10T202621_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 20:26:21.808913</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T202622_model.h5</td>\n",
       "      <td>models/2019-10-10T202622_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 20:26:22.799794</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-10-10T202627_model.h5</td>\n",
       "      <td>models/2019-10-10T202627_model.h5</td>\n",
       "      <td>{'keras', 'tensorflow'}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-10 20:26:27.330631</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epochs layers                  model_name  \\\n",
       "0       1     []  2019-10-10T202614_model.h5   \n",
       "1       1     []  2019-10-10T202617_model.h5   \n",
       "2       1     []  2019-10-10T202618_model.h5   \n",
       "3       1     []  2019-10-10T202619_model.h5   \n",
       "4       1     []  2019-10-10T202620_model.h5   \n",
       "5       1     []  2019-10-10T202621_model.h5   \n",
       "6       1     []  2019-10-10T202622_model.h5   \n",
       "7       1     []  2019-10-10T202627_model.h5   \n",
       "\n",
       "                          model_path               model_tags  num_layers  \\\n",
       "0  models/2019-10-10T202614_model.h5  {'keras', 'tensorflow'}           0   \n",
       "1  models/2019-10-10T202617_model.h5  {'keras', 'tensorflow'}           0   \n",
       "2  models/2019-10-10T202618_model.h5  {'keras', 'tensorflow'}           0   \n",
       "3  models/2019-10-10T202619_model.h5  {'keras', 'tensorflow'}           0   \n",
       "4  models/2019-10-10T202620_model.h5  {'keras', 'tensorflow'}           0   \n",
       "5  models/2019-10-10T202621_model.h5  {'keras', 'tensorflow'}           0   \n",
       "6  models/2019-10-10T202622_model.h5  {'keras', 'tensorflow'}           0   \n",
       "7  models/2019-10-10T202627_model.h5  {'keras', 'tensorflow'}           0   \n",
       "\n",
       "   optimizer  score                   timestamp  train_size  validation_size  \n",
       "0          1      1  2019-10-10 20:26:14.109413           1                1  \n",
       "1          1      1  2019-10-10 20:26:17.506235           1                1  \n",
       "2          1      1  2019-10-10 20:26:18.759291           1                1  \n",
       "3          1      1  2019-10-10 20:26:19.641559           1                1  \n",
       "4          1      1  2019-10-10 20:26:20.819121           1                1  \n",
       "5          1      1  2019-10-10 20:26:21.808913           1                1  \n",
       "6          1      1  2019-10-10 20:26:22.799794           1                1  \n",
       "7          1      1  2019-10-10 20:26:27.330631           1                1  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# root = 'models/'\n",
    "# save_as_type = 'h5' # can choose 'h5' or 'tf'\n",
    "# model_records_path = root+'model_records.csv'\n",
    "\n",
    "# df = pd.read_csv(model_records_path)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model, if starting from a pre-made model\n",
    "# root = 'models/'\n",
    "# records_df, model = load_model(model_file_path=\"models/2019-10-11T004440_model.h5\", model_output=True)\n",
    "\n",
    "# from keras.initializers import glorot_uniform\n",
    "\n",
    "# from keras.models import load_model\n",
    "# from keras.utils import CustomObjectScope\n",
    "# from keras.initializers import glorot_uniform\n",
    "# with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "#         loaded_model = keras.models.load_model('models/2019-10-11T004440_model.h5')\n",
    "\n",
    "# model = keras.models.load_model('models/2019-10-11T004440_model.h5',custom_objects={\"GlorotUniform\": keras.initializers.glorot_uniform})\n",
    "\n",
    "# custom_objects={\"GlorotUniform\": tf.keras.initializers.glorot_uniform}\n",
    "\n",
    "# from keras.models import load_model\n",
    "# from keras.utils import CustomObjectScope\n",
    "\n",
    "# with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "\n",
    "#         model = load_model('imdb_mlp_model.h5')\n",
    "\n",
    "# root = 'models/'\n",
    "\n",
    "# save_as_type = 'h5' # can choose 'h5' or 'tf'\n",
    "# model_records_path = root+'model_records.csv'\n",
    "\n",
    "# df = pd.read_csv(model_records_path)\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-10-10T195147'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d = date.today()\n",
    "from datetime import datetime\n",
    "d = datetime.utcnow()\n",
    "d.isoformat()\n",
    "d.strftime(\"%Y-%m-%dT%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
